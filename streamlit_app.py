import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.feature_extraction.text import TfidfVectorizer
import re
from collections import Counter
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import base64
import time
import json

# Importa√ß√£o condicional da OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    st.warning("‚ö†Ô∏è OpenAI n√£o instalado. Usando apenas m√©todo tradicional.")


class PriorityMatrix:
    """Classe para gerenciar a Matriz de Impacto x Urg√™ncia"""
    
    def __init__(self):
        # Matriz de SLA (horas)
        self.sla_matrix = {
            1: {1: 2, 2: 4, 3: 8, 4: 24, 5: 48},
            2: {1: 4, 2: 8, 3: 24, 4: 48, 5: 120},
            3: {1: 8, 2: 24, 3: 48, 4: 120, 5: 240},
            4: {1: 24, 2: 48, 3: 120, 4: 120, 5: 240},
            5: {1: 48, 2: 120, 3: 120, 4: 240, 5: 240}
        }
        
        # Matriz de Prioridade
        self.priority_matrix = {
            1: {1: 'P1', 2: 'P2', 3: 'P3', 4: 'P4', 5: 'P5'},
            2: {1: 'P2', 2: 'P3', 3: 'P4', 4: 'P5', 5: 'Planejado'},
            3: {1: 'P3', 2: 'P4', 3: 'P5', 4: 'Planejado', 5: 'Backlog'},
            4: {1: 'P4', 2: 'P5', 3: 'Planejado', 4: 'Planejado', 5: 'Backlog'},
            5: {1: 'P5', 2: 'Planejado', 3: 'Planejado', 4: 'Planejado', 5: 'Backlog'}
        }
        
        # Palavras-chave para classifica√ß√£o autom√°tica de Impacto
        self.impacto_keywords = {
            1: ['financeiro', 'faturamento', 'boleto', 'pagamento', 'reembolso', 'nota fiscal', 'api', 'integra√ß√£o', 'produ√ß√£o', 'parado', 'travado', 'fora'],
            2: ['vendas', 'comercial', 'parceiro', 'cliente', 'sistema principal'],
            3: ['administrativo', 'relat√≥rio', 'interno', 'time'],
            4: ['exibi√ß√£o', 'visual', 'tela', 'erro pontual'],
            5: ['melhoria', 'est√©tica', 'cosm√©tico', 'sugest√£o']
        }
        
        # Palavras-chave para classifica√ß√£o autom√°tica de Urg√™ncia
        self.urgencia_keywords = {
            1: ['imediatamente', 'urgente', 'cr√≠tico', 'bloqueado', 'parado', 'fora'],
            2: ['hoje', 'ainda hoje', 'agora', 'rapidamente'],
            3: ['48h', 'dois dias', 'retrabalho'],
            4: ['semana', 'impacto baixo'],
            5: ['planejado', 'agendamento', 'futuro', 'quando poss√≠vel']
        }
    
    def classify_impact(self, title, keywords):
        """Classifica o impacto baseado no t√≠tulo do chamado"""
        if pd.isna(title):
            return 3
        
        title_lower = str(title).lower()
        
        for impact_level, words in self.impacto_keywords.items():
            for word in words:
                if word in title_lower:
                    return impact_level
        
        # An√°lise adicional por palavras-chave do cluster
        if keywords:
            keywords_str = ' '.join(keywords).lower()
            for impact_level, words in self.impacto_keywords.items():
                for word in words:
                    if word in keywords_str:
                        return impact_level
        
        return 3  # Impacto m√©dio por padr√£o
    
    def classify_urgency(self, title):
        """Classifica a urg√™ncia baseada no t√≠tulo do chamado"""
        if pd.isna(title):
            return 3
        
        title_lower = str(title).lower()
        
        for urgency_level, words in self.urgencia_keywords.items():
            for word in words:
                if word in title_lower:
                    return urgency_level
        
        return 3  # Urg√™ncia m√©dia por padr√£o
    
    def get_priority_and_sla(self, impacto, urgencia):
        """Retorna prioridade e SLA baseado na matriz"""
        priority = self.priority_matrix[impacto][urgencia]
        sla_hours = self.sla_matrix[impacto][urgencia]
        return priority, sla_hours
    
    def format_sla(self, sla_hours):
        """Formata SLA em formato leg√≠vel"""
        if sla_hours < 24:
            return f"{sla_hours}h"
        else:
            days = sla_hours // 24
            return f"{days}d"


class GLPIClusteringSystem:
    def __init__(self, use_openai=True):
        self.use_openai = use_openai and OPENAI_AVAILABLE
        self.client = None
        self.kmeans = None
        self.clusters_info = {}
        self.embeddings = None
        self.priority_matrix = PriorityMatrix()
        
        # Configurar OpenAI se dispon√≠vel
        if self.use_openai:
            try:
                # Verificar se a chave existe nos secrets
                if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
                    api_key = st.secrets['OPENAI_API_KEY']
                    if api_key and api_key.startswith('sk-'):
                        self.client = OpenAI(api_key=api_key)
                        st.success("‚úÖ OpenAI configurado com sucesso!")
                    else:
                        st.warning("‚ö†Ô∏è Chave da OpenAI inv√°lida. Usando m√©todo tradicional.")
                        self.use_openai = False
                else:
                    st.info("‚ÑπÔ∏è Chave da OpenAI n√£o encontrada. Usando m√©todo tradicional.")
                    self.use_openai = False
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro ao configurar OpenAI: {str(e)}. Usando m√©todo tradicional.")
                self.use_openai = False
                self.client = None
        
    def preprocess_text(self, text):
        """Pr√©-processamento espec√≠fico para t√≠tulos de chamados t√©cnicos"""
        if pd.isna(text) or text == '':
            return ''
        
        # Converter para min√∫sculas mantendo estrutura t√©cnica
        text = str(text).lower()
        
        # Manter separadores importantes (|, -, /)
        text = re.sub(r'[^\w\s\|\-\/\.]', ' ', text)
        
        # Remover espa√ßos extras
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def extract_system_prefix(self, title):
        """Extrai o prefixo do sistema (WA, SQ, Sistema, etc.)"""
        if pd.isna(title):
            return 'Outros'
        
        title_str = str(title).strip()
        
        # Padr√µes comuns identificados nos dados
        if title_str.startswith('WA |'):
            return 'WA'
        elif title_str.startswith('SQ |'):
            return 'SQ'
        elif title_str.startswith('Sistema -'):
            # Extrai o subsistema
            parts = title_str.split(' - ')
            if len(parts) > 1:
                subsystem = parts[1].split(' ')[0]
                return f"Sistema - {subsystem}"
            return 'Sistema'
        else:
            return 'Outros'
    
    def get_openai_embeddings(self, texts, batch_size=50):
        """Obt√©m embeddings usando OpenAI API com rate limiting"""
        if not self.client:
            raise ValueError("Cliente OpenAI n√£o configurado")
        
        embeddings = []
        
        # Processar em lotes menores para evitar rate limits
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            try:
                with st.spinner(f"Obtendo embeddings {i+1}-{min(i+batch_size, len(texts))} de {len(texts)}..."):
                    response = self.client.embeddings.create(
                        model="text-embedding-3-small",
                        input=batch,
                        encoding_format="float"
                    )
                    
                    batch_embeddings = [data.embedding for data in response.data]
                    embeddings.extend(batch_embeddings)
                    
                    # Rate limiting - pausa entre lotes
                    if i + batch_size < len(texts):
                        time.sleep(0.5)
                        
            except Exception as e:
                st.error(f"Erro ao obter embeddings: {str(e)}")
                st.info("Tentando com m√©todo tradicional...")
                raise e
        
        return np.array(embeddings)
    
    def get_traditional_embeddings(self, texts):
        """M√©todo tradicional usando TF-IDF como fallback"""
        from sklearn.feature_extraction.text import TfidfVectorizer
        
        vectorizer = TfidfVectorizer(
            max_features=500,
            stop_words=None,
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.8
        )
        
        X = vectorizer.fit_transform(texts)
        return X.toarray()
    
    def determine_optimal_clusters(self, X, max_clusters=15):
        """Determina o n√∫mero √≥timo de clusters usando m√©todo do cotovelo e silhouette"""
        silhouette_scores = []
        inertias = []
        k_range = range(2, min(max_clusters + 1, len(X)))
        
        with st.spinner("Determinando n√∫mero √≥timo de clusters..."):
            for k in k_range:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                cluster_labels = kmeans.fit_predict(X)
                silhouette_avg = silhouette_score(X, cluster_labels)
                silhouette_scores.append(silhouette_avg)
                inertias.append(kmeans.inertia_)
        
        # Escolhe o k com melhor silhouette score
        best_k = k_range[np.argmax(silhouette_scores)]
        return best_k, silhouette_scores, inertias
    
    def generate_cluster_name_with_ai(self, cluster_titles, cluster_id):
        """Gera nome do cluster usando OpenAI"""
        if not self.client:
            return None
        
        try:
            # Prepara os t√≠tulos mais representativos
            sample_titles = cluster_titles[:8]  # Reduzido para evitar tokens em excesso
            titles_text = "\n".join([f"- {title}" for title in sample_titles])
            
            prompt = f"""Analise os t√≠tulos de chamados t√©cnicos e crie um nome descritivo:

{titles_text}

Crie um nome conciso (m√°ximo 4 palavras) que represente o tema principal.
Responda apenas com o nome, sem explica√ß√µes."""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em an√°lise de chamados t√©cnicos."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=30,
                temperature=0.1
            )
            
            cluster_name = response.choices[0].message.content.strip()
            return cluster_name if cluster_name else None
            
        except Exception as e:
            st.warning(f"Erro ao gerar nome com AI para cluster {cluster_id}: {str(e)}")
            return None
    
    def classify_cluster_priority(self, cluster_data, cluster_info):
        """Classifica prioridade do cluster baseado nos chamados"""
        titles = cluster_data['T√≠tulo'].tolist()
        keywords = cluster_info.get('keywords', [])
        
        # Classificar impacto e urg√™ncia para cada chamado do cluster
        impacts = [self.priority_matrix.classify_impact(title, keywords) for title in titles]
        urgencies = [self.priority_matrix.classify_urgency(title) for title in titles]
        
        # Usar o impacto e urg√™ncia mais comuns no cluster
        most_common_impact = max(set(impacts), key=impacts.count)
        most_common_urgency = max(set(urgencies), key=urgencies.count)
        
        priority, sla_hours = self.priority_matrix.get_priority_and_sla(most_common_impact, most_common_urgency)
        
        return {
            'impacto_padrao': most_common_impact,
            'urgencia_padrao': most_common_urgency,
            'prioridade_padrao': priority,
            'sla_padrao': sla_hours,
            'sla_formatado': self.priority_matrix.format_sla(sla_hours)
        }
    
    def fit_clusters(self, df, titulo_col='T√≠tulo', auto_clusters=True, n_clusters=8):
        """Ajusta o modelo de clusteriza√ß√£o aos dados"""
        # Pr√©-processamento
        df = df.copy()
        df['titulo_processado'] = df[titulo_col].apply(self.preprocess_text)
        df['sistema_prefix'] = df[titulo_col].apply(self.extract_system_prefix)
        
        # Remove t√≠tulos vazios
        df_clean = df[df['titulo_processado'] != ''].copy()
        
        if len(df_clean) == 0:
            raise ValueError("Nenhum t√≠tulo v√°lido encontrado para clusteriza√ß√£o")
        
        # Obter embeddings
        texts = df_clean['titulo_processado'].tolist()
        
        if self.use_openai and self.client:
            try:
                # Usar embeddings da OpenAI
                st.info("ü§ñ Usando embeddings da OpenAI para melhor precis√£o...")
                X = self.get_openai_embeddings(texts)
                st.success("‚úÖ Embeddings da OpenAI obtidos com sucesso!")
            except Exception as e:
                st.warning("‚ö†Ô∏è Erro com OpenAI, usando m√©todo tradicional...")
                X = self.get_traditional_embeddings(texts)
        else:
            # Usar m√©todo tradicional
            st.info("üìä Usando m√©todo tradicional TF-IDF...")
            X = self.get_traditional_embeddings(texts)
        
        # Salvar embeddings
        self.embeddings = X
        
        # Determina√ß√£o do n√∫mero de clusters
        if auto_clusters:
            optimal_k, silhouette_scores, inertias = self.determine_optimal_clusters(X)
            n_clusters = optimal_k
            st.info(f"üéØ N√∫mero √≥timo de clusters determinado: {n_clusters}")
        
        # Aplica√ß√£o do K-Means
        with st.spinner("Executando algoritmo de clusteriza√ß√£o..."):
            self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            clusters = self.kmeans.fit_predict(X)
        
        # Adiciona clusters ao DataFrame
        df_clean['cluster'] = clusters
        
        # An√°lise dos clusters
        self.analyze_clusters(df_clean)
        
        # Aplicar classifica√ß√£o de prioridade
        self.apply_priority_classification(df_clean)
        
        return df_clean
    
    def analyze_clusters(self, df):
        """Analisa e nomeia os clusters baseado no conte√∫do"""
        self.clusters_info = {}
        
        with st.spinner("Analisando e nomeando clusters..."):
            for cluster_id in sorted(df['cluster'].unique()):
                cluster_data = df[df['cluster'] == cluster_id]
                
                # T√≠tulos mais comuns no cluster
                titulos_originais = cluster_data['T√≠tulo'].value_counts().head(10)
                
                # Sistemas mais comuns
                sistemas = cluster_data['sistema_prefix'].value_counts()
                
                # Palavras-chave mais importantes
                titulos_cluster = cluster_data['titulo_processado'].tolist()
                all_words = ' '.join(titulos_cluster).split()
                word_freq = Counter(all_words)
                keywords = [word for word, freq in word_freq.most_common(15) 
                           if len(word) > 2 and word not in ['sistema', 'tela', 'para', 'com', 'por', 'dos', 'das']]
                
                # Tentar gerar nome com AI primeiro
                ai_name = None
                if self.use_openai and self.client:
                    ai_name = self.generate_cluster_name_with_ai(titulos_originais.index.tolist(), cluster_id)
                
                # Nome do cluster
                if ai_name:
                    cluster_name = ai_name
                else:
                    # Fallback para m√©todo tradicional
                    sistema_principal = sistemas.index[0] if not sistemas.empty else 'Geral'
                    keyword_principal = keywords[0] if keywords else 'Diversos'
                    cluster_name = f"{sistema_principal} - {keyword_principal.title()}"
                
                # An√°lise de urg√™ncia e status se dispon√≠vel
                urgencia_dist = {}
                status_dist = {}
                
                if 'Urg√™ncia' in cluster_data.columns:
                    urgencia_dist = cluster_data['Urg√™ncia'].value_counts().to_dict()
                
                if 'Status' in cluster_data.columns:
                    status_dist = cluster_data['Status'].value_counts().to_dict()
                
                self.clusters_info[cluster_id] = {
                    'nome': cluster_name,
                    'total_chamados': len(cluster_data),
                    'sistema_principal': sistemas.index[0] if not sistemas.empty else 'Geral',
                    'keywords': keywords[:8],
                    'exemplos_titulos': titulos_originais.index.tolist()[:5],
                    'distribuicao_sistemas': sistemas.to_dict(),
                    'urgencia_distribuicao': urgencia_dist,
                    'status_distribuicao': status_dist,
                    'usado_ai': ai_name is not None
                }
    
    def apply_priority_classification(self, df):
        """Aplica classifica√ß√£o de prioridade aos clusters e chamados"""
        # Adicionar colunas de prioridade ao DataFrame
        df['Impacto'] = 0
        df['Urgencia'] = 0
        df['Prioridade'] = ''
        df['SLA_Horas'] = 0
        df['SLA_Formatado'] = ''
        
        with st.spinner("Aplicando classifica√ß√£o de prioridade..."):
            for cluster_id in df['cluster'].unique():
                cluster_data = df[df['cluster'] == cluster_id]
                cluster_info = self.clusters_info[cluster_id]
                
                # Classificar prioridade do cluster
                priority_info = self.classify_cluster_priority(cluster_data, cluster_info)
                
                # Adicionar informa√ß√µes de prioridade ao cluster_info
                self.clusters_info[cluster_id].update(priority_info)
                
                # Aplicar classifica√ß√£o individual para cada chamado
                for idx in cluster_data.index:
                    titulo = df.loc[idx, 'T√≠tulo']
                    
                    # Classifica√ß√£o individual
                    impacto = self.priority_matrix.classify_impact(titulo, cluster_info['keywords'])
                    urgencia = self.priority_matrix.classify_urgency(titulo)
                    prioridade, sla_horas = self.priority_matrix.get_priority_and_sla(impacto, urgencia)
                    sla_formatado = self.priority_matrix.format_sla(sla_horas)
                    
                    # Atualizar DataFrame
                    df.loc[idx, 'Impacto'] = impacto
                    df.loc[idx, 'Urgencia'] = urgencia
                    df.loc[idx, 'Prioridade'] = prioridade
                    df.loc[idx, 'SLA_Horas'] = sla_horas
                    df.loc[idx, 'SLA_Formatado'] = sla_formatado
    
    def predict_cluster(self, new_titles):
        """Prediz cluster para novos t√≠tulos"""
        if self.kmeans is None:
            raise ValueError("Modelo n√£o foi treinado. Execute fit_clusters primeiro.")
        
        processed_titles = [self.preprocess_text(title) for title in new_titles]
        
        # Obter embeddings para novos t√≠tulos
        if self.use_openai and self.client:
            try:
                X_new = self.get_openai_embeddings(processed_titles)
            except:
                X_new = self.get_traditional_embeddings(processed_titles)
        else:
            X_new = self.get_traditional_embeddings(processed_titles)
        
        clusters = self.kmeans.predict(X_new)
        return clusters
    
    def get_cluster_summary(self):
        """Retorna resumo dos clusters"""
        if not self.clusters_info:
            return pd.DataFrame()
        
        summary_data = []
        for cluster_id, info in self.clusters_info.items():
            summary_data.append({
                'Cluster_ID': cluster_id,
                'Nome_Cluster': info['nome'],
                'Total_Chamados': info['total_chamados'],
                'Sistema_Principal': info['sistema_principal'],
                'Palavras_Chave': ', '.join(info['keywords'][:5]),
                'Exemplo_Titulo': info['exemplos_titulos'][0] if info['exemplos_titulos'] else '',
                'Prioridade_Padrao': info.get('prioridade_padrao', 'P3'),
                'SLA_Padrao': info.get('sla_formatado', '8h'),
                'IA_Usado': 'ü§ñ' if info['usado_ai'] else 'üìä'
            })
        
        return pd.DataFrame(summary_data)
    
    def get_priority_matrix_data(self, df):
        """Retorna dados para visualiza√ß√£o da matriz de prioridade"""
        if df.empty:
            return pd.DataFrame()
        
        # Criar matriz de contagem
        matrix_data = []
        for impacto in range(1, 6):
            for urgencia in range(1, 6):
                count = len(df[(df['Impacto'] == impacto) & (df['Urgencia'] == urgencia)])
                priority, sla_hours = self.priority_matrix.get_priority_and_sla(impacto, urgencia)
                sla_formatted = self.priority_matrix.format_sla(sla_hours)
                
                matrix_data.append({
                    'Impacto': impacto,
                    'Urgencia': urgencia,
                    'Quantidade': count,
                    'Prioridade': priority,
                    'SLA': sla_formatted
                })
        
        return pd.DataFrame(matrix_data)


def create_download_link(df, filename):
    """Cria link para download do DataFrame como Excel"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='Chamados_Clusterizados', index=False)
        
        # Adicionar uma aba com resumo dos clusters se dispon√≠vel
        if 'clustering_system' in st.session_state:
            cluster_summary = st.session_state['clustering_system'].get_cluster_summary()
            cluster_summary.to_excel(writer, sheet_name='Resumo_Clusters', index=False)
            
            # Adicionar aba com matriz de prioridade
            if 'df_clustered' in st.session_state:
                df_clustered = st.session_state['df_clustered']
                matrix_data = st.session_state['clustering_system'].get_priority_matrix_data(df_clustered)
                matrix_data.to_excel(writer, sheet_name='Matriz_Prioridade', index=False)
    
    output.seek(0)
    b64 = base64.b64encode(output.read()).decode()
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">üì• Download Excel com Clusters</a>'
    return href


def main():
    st.set_page_config(
        page_title="GLPI - Sistema de Clusteriza√ß√£o de Chamados",
        page_icon="üéØ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Header
    st.title("üéØ Sistema de Clusteriza√ß√£o de Chamados GLPI feito para o IAGO")
    st.markdown("Sistema inteligente para agrupamento autom√°tico de chamados usando IA")
    st.markdown("---")
    
    # Verificar configura√ß√£o da OpenAI
    openai_configured = False
    if OPENAI_AVAILABLE and hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
        api_key = st.secrets.get('OPENAI_API_KEY', '')
        if api_key and api_key.startswith('sk-'):
            openai_configured = True
            st.sidebar.success("ü§ñ OpenAI configurado")
        else:
            st.sidebar.warning("‚ö†Ô∏è Chave OpenAI inv√°lida")
    else:
        st.sidebar.warning("‚ö†Ô∏è OpenAI n√£o configurado")
        if not OPENAI_AVAILABLE:
            st.sidebar.info("Instale: pip install openai")
        else:
            st.sidebar.info("Adicione OPENAI_API_KEY nos secrets")
    
    # Sidebar para configura√ß√µes
    st.sidebar.header("‚öôÔ∏è Configura√ß√µes")
    
    # Op√ß√£o de usar OpenAI
    use_openai = st.sidebar.checkbox(
        "ü§ñ Usar OpenAI para embeddings", 
        value=openai_configured,
        disabled=not openai_configured,
        help="Melhora a precis√£o da clusteriza√ß√£o usando embeddings da OpenAI"
    )
    
    # Upload do arquivo
    uploaded_file = st.file_uploader(
        "üìÅ Carregue o arquivo CSV/Excel dos chamados",
        type=['csv', 'xlsx', 'xls'],
        help="Arquivo deve conter uma coluna 'T√≠tulo' com os t√≠tulos dos chamados"
    )
    
    if uploaded_file is not None:
        try:
            # Leitura do arquivo
            if uploaded_file.name.endswith('.csv'):
                # Tentar diferentes delimitadores
                try:
                    df = pd.read_csv(uploaded_file, sep=';', encoding='utf-8')
                except:
                    df = pd.read_csv(uploaded_file, sep=',', encoding='utf-8')
            else:
                df = pd.read_excel(uploaded_file)
            
            st.success(f"‚úÖ Arquivo carregado com sucesso! {len(df)} registros encontrados.")
            
            # Mostrar preview dos dados
            with st.expander("üëÄ Preview dos Dados", expanded=False):
                st.dataframe(df.head(10), use_container_width=True)
                st.info(f"Colunas encontradas: {', '.join(df.columns)}")
            
            # Verifica√ß√£o da coluna T√≠tulo
            if 'T√≠tulo' not in df.columns:
                st.error("‚ùå Coluna 'T√≠tulo' n√£o encontrada no arquivo.")
                st.write("**Colunas dispon√≠veis:**", list(df.columns))
                st.stop()
            
            # Estat√≠sticas b√°sicas
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìä Total de Registros", len(df))
            with col2:
                titulos_validos = df['T√≠tulo'].notna().sum()
                st.metric("üìù T√≠tulos V√°lidos", titulos_validos)
            with col3:
                if 'Urg√™ncia' in df.columns:
                    alta_urgencia = (df['Urg√™ncia'] == 'Alta').sum()
                    st.metric("üî• Alta Urg√™ncia", alta_urgencia)
            
            # Configura√ß√µes do clustering
            st.sidebar.subheader("üîß Par√¢metros de Clustering")
            auto_clusters = st.sidebar.checkbox("Determinar clusters automaticamente", value=True)
            
            if not auto_clusters:
                n_clusters = st.sidebar.slider("N√∫mero de clusters", min_value=2, max_value=20, value=8)
            else:
                n_clusters = 8
            
            # Bot√£o para executar clustering
            if st.sidebar.button("üöÄ Executar Clusteriza√ß√£o", type="primary"):
                try:
                    with st.spinner("Processando clusteriza√ß√£o..."):
                        # Inicializa o sistema
                        clustering_system = GLPIClusteringSystem(use_openai=use_openai)
                        
                        # Executa clustering
                        df_clustered = clustering_system.fit_clusters(
                            df, 
                            auto_clusters=auto_clusters, 
                            n_clusters=n_clusters
                        )
                        
                        # Salva resultados na sess√£o
                        st.session_state['df_clustered'] = df_clustered
                        st.session_state['clustering_system'] = clustering_system
                        st.session_state['clusters_info'] = clustering_system.clusters_info
                        st.session_state['use_openai'] = use_openai
                    
                    st.success("‚úÖ Clusteriza√ß√£o conclu√≠da com sucesso!")
                    st.experimental_rerun()
                    
                except Exception as e:
                    st.error(f"‚ùå Erro durante a clusteriza√ß√£o: {str(e)}")
                    st.exception(e)
            
            # Mostra resultados se dispon√≠veis
            if 'df_clustered' in st.session_state:
                df_clustered = st.session_state['df_clustered']
                clustering_system = st.session_state['clustering_system']
                
                # M√©tricas principais
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("üìä Total de Chamados", len(df_clustered))
                
                with col2:
                    st.metric("üéØ Clusters Identificados", len(clustering_system.clusters_info))
                
                with col3:
                    avg_per_cluster = len(df_clustered) / len(clustering_system.clusters_info)
                    st.metric("üìà M√©dia por Cluster", f"{avg_per_cluster:.1f}")
                
                with col4:
                    ai_clusters = sum(1 for info in clustering_system.clusters_info.values() if info['usado_ai'])
                    st.metric("ü§ñ Clusters com IA", f"{ai_clusters}/{len(clustering_system.clusters_info)}")
                
                # Tabs para visualiza√ß√£o
                tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                    "üìã Resumo dos Clusters", 
                    "üß≠ Matriz de Prioridade",
                    "üìä Visualiza√ß√µes", 
                    "üìù Dados Detalhados", 
                    "üéØ Recomenda√ß√µes",
                    "üì• Download"
                ])
                
                with tab1:
                    st.subheader("üìã Resumo dos Clusters Identificados")
                    
                    cluster_summary = clustering_system.get_cluster_summary()
                    st.dataframe(cluster_summary, use_container_width=True)
                    
                    # Detalhes de cada cluster
                    st.subheader("üîç Detalhes dos Clusters")
                    
                    for cluster_id, info in clustering_system.clusters_info.items():
                        with st.expander(f"Cluster {cluster_id}: {info['nome']} ({info['total_chamados']} chamados) {'ü§ñ' if info['usado_ai'] else 'üìä'}"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.write("**Palavras-chave:**")
                                st.write(", ".join(info['keywords']))
                                
                                st.write("**Sistema Principal:**")
                                st.write(info['sistema_principal'])
                                
                                st.write("**Prioridade Padr√£o:**")
                                priority_info = info.get('prioridade_padrao', 'P3')
                                sla_info = info.get('sla_formatado', '8h')
                                st.write(f"{priority_info} - SLA: {sla_info}")
                                
                                if info['urgencia_distribuicao']:
                                    st.write("**Distribui√ß√£o de Urg√™ncia:**")
                                    for urgencia, count in info['urgencia_distribuicao'].items():
                                        st.write(f"‚Ä¢ {urgencia}: {count}")
                            
                            with col2:
                                st.write("**Exemplos de T√≠tulos:**")
                                for titulo in info['exemplos_titulos']:
                                    st.write(f"‚Ä¢ {titulo}")
                
                with tab2:
                    st.subheader("üß≠ Matriz de Impacto x Urg√™ncia")
                    
                    # M√©tricas de prioridade
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        p1_count = len(df_clustered[df_clustered['Prioridade'] == 'P1'])
                        st.metric("üî• P1 - Cr√≠tico", p1_count)
                    
                    with col2:
                        p2_count = len(df_clustered[df_clustered['Prioridade'] == 'P2'])
                        st.metric("üö® P2 - Alto", p2_count)
                    
                    with col3:
                        p3_count = len(df_clustered[df_clustered['Prioridade'] == 'P3'])
                        st.metric("‚ö†Ô∏è P3 - M√©dio", p3_count)
                    
                    with col4:
                        p4_p5_count = len(df_clustered[df_clustered['Prioridade'].isin(['P4', 'P5'])])
                        st.metric("üìã P4/P5 - Baixo", p4_p5_count)
                    
                    # Matriz visual
                    matrix_data = clustering_system.get_priority_matrix_data(df_clustered)
                    
                    if not matrix_data.empty:
                        # Criar matriz pivot para visualiza√ß√£o
                        pivot_data = matrix_data.pivot(index='Impacto', columns='Urgencia', values='Quantidade').fillna(0)
                        
                        # Heatmap da matriz
                        fig_matrix = px.imshow(
                            pivot_data.values,
                            x=[f"Urg√™ncia {i}" for i in range(1, 6)],
                            y=[f"Impacto {i}" for i in range(1, 6)],
                            color_continuous_scale='Reds',
                            title="Distribui√ß√£o de Chamados na Matriz Impacto x Urg√™ncia"
                        )
                        
                        # Adicionar texto nas c√©lulas
                        for i in range(len(pivot_data.index)):
                            for j in range(len(pivot_data.columns)):
                                count = int(pivot_data.iloc[i, j])
                                impacto = pivot_data.index[i]
                                urgencia = pivot_data.columns[j]
                                priority, sla_hours = clustering_system.priority_matrix.get_priority_and_sla(impacto, urgencia)
                                sla_formatted = clustering_system.priority_matrix.format_sla(sla_hours)
                                
                                fig_matrix.add_annotation(
                                    x=j, y=i,
                                    text=f"{count}<br>{priority}<br>{sla_formatted}",
                                    showarrow=False,
                                    font=dict(color="white" if count > pivot_data.values.max()/2 else "black")
                                )
                        
                        st.plotly_chart(fig_matrix, use_container_width=True)
                    
                    # Tabela da matriz de refer√™ncia
                    st.subheader("üìä Tabela de Refer√™ncia - SLA por Prioridade")
                    
                    # Criar tabela de refer√™ncia
                    reference_data = []
                    for impacto in range(1, 6):
                        for urgencia in range(1, 6):
                            priority, sla_hours = clustering_system.priority_matrix.get_priority_and_sla(impacto, urgencia)
                            sla_formatted = clustering_system.priority_matrix.format_sla(sla_hours)
                            count = len(df_clustered[(df_clustered['Impacto'] == impacto) & (df_clustered['Urgencia'] == urgencia)])
                            
                            reference_data.append({
                                'Impacto': impacto,
                                'Urg√™ncia': urgencia,
                                'Prioridade': priority,
                                'SLA': sla_formatted,
                                'Quantidade_Chamados': count
                            })
                    
                    reference_df = pd.DataFrame(reference_data)
                    st.dataframe(reference_df, use_container_width=True)
                    
                    # Distribui√ß√£o por prioridade
                    st.subheader("üìà Distribui√ß√£o por Prioridade")
                    priority_counts = df_clustered['Prioridade'].value_counts()
                    
                    fig_priority = px.bar(
                        x=priority_counts.index,
                        y=priority_counts.values,
                        title="Distribui√ß√£o de Chamados por Prioridade",
                        color=priority_counts.values,
                        color_continuous_scale='RdYlBu_r'
                    )
                    st.plotly_chart(fig_priority, use_container_width=True)
                
                with tab3:
                    st.subheader("üìä Visualiza√ß√µes dos Clusters")
                    
                    # Gr√°fico de distribui√ß√£o dos clusters
                    cluster_counts = df_clustered['cluster'].value_counts().sort_index()
                    cluster_names = [f"C{i}: {clustering_system.clusters_info[i]['nome']}" for i in cluster_counts.index]
                    
                    fig_bar = px.bar(
                        x=cluster_names,
                        y=cluster_counts.values,
                        title="Distribui√ß√£o de Chamados por Cluster",
                        labels={'x': 'Clusters', 'y': 'N√∫mero de Chamados'},
                        color=cluster_counts.values,
                        color_continuous_scale='viridis'
                    )
                    fig_bar.update_layout(xaxis_tickangle=45)
                    st.plotly_chart(fig_bar, use_container_width=True)
                    
                    # Gr√°ficos em duas colunas
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Gr√°fico de pizza dos sistemas
                        sistema_counts = df_clustered['sistema_prefix'].value_counts()
                        fig_pie = px.pie(
                            values=sistema_counts.values,
                            names=sistema_counts.index,
                            title="Distribui√ß√£o por Sistema"
                        )
                        st.plotly_chart(fig_pie, use_container_width=True)
                    
                    with col2:
                        # Gr√°fico de urg√™ncia se dispon√≠vel
                        if 'Urg√™ncia' in df_clustered.columns:
                            urgencia_counts = df_clustered['Urg√™ncia'].value_counts()
                            fig_urgencia = px.bar(
                                x=urgencia_counts.index,
                                y=urgencia_counts.values,
                                title="Distribui√ß√£o por Urg√™ncia",
                                color=urgencia_counts.values,
                                color_continuous_scale='reds'
                            )
                            st.plotly_chart(fig_urgencia, use_container_width=True)
                
                with tab4:
                    st.subheader("üìù Dados Detalhados com Clusters")
                    
                    # Filtros
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        cluster_filter = st.multiselect(
                            "Filtrar por Cluster:",
                            options=sorted(df_clustered['cluster'].unique()),
                            default=sorted(df_clustered['cluster'].unique())
                        )
                    
                    with col2:
                        sistema_filter = st.multiselect(
                            "Filtrar por Sistema:",
                            options=sorted(df_clustered['sistema_prefix'].unique()),
                            default=sorted(df_clustered['sistema_prefix'].unique())
                        )
                    
                    with col3:
                        prioridade_filter = st.multiselect(
                            "Filtrar por Prioridade:",
                            options=sorted(df_clustered['Prioridade'].unique()),
                            default=sorted(df_clustered['Prioridade'].unique())
                        )
                    
                    with col4:
                        if 'Urg√™ncia' in df_clustered.columns:
                            urgencia_filter = st.multiselect(
                                "Filtrar por Urg√™ncia:",
                                options=sorted(df_clustered['Urg√™ncia'].unique()),
                                default=sorted(df_clustered['Urg√™ncia'].unique())
                            )
                        else:
                            urgencia_filter = []
                    
                    # Aplicar filtros
                    df_filtered = df_clustered[df_clustered['cluster'].isin(cluster_filter)]
                    df_filtered = df_filtered[df_filtered['sistema_prefix'].isin(sistema_filter)]
                    df_filtered = df_filtered[df_filtered['Prioridade'].isin(prioridade_filter)]
                    
                    if urgencia_filter and 'Urg√™ncia' in df_clustered.columns:
                        df_filtered = df_filtered[df_filtered['Urg√™ncia'].isin(urgencia_filter)]
                    
                    # Adicionar nome do cluster
                    df_filtered['Nome_Cluster'] = df_filtered['cluster'].map(
                        lambda x: clustering_system.clusters_info[x]['nome']
                    )
                    
                    # Reorganizar colunas
                    cols_order = ['ID', 'T√≠tulo', 'cluster', 'Nome_Cluster', 'sistema_prefix', 'Prioridade', 'SLA_Formatado', 'Impacto', 'Urgencia']
                    if 'Urg√™ncia' in df_filtered.columns:
                        cols_order.append('Urg√™ncia')
                    if 'Status' in df_filtered.columns:
                        cols_order.append('Status')
                    
                    # Adicionar outras colunas
                    cols_order += [col for col in df_filtered.columns 
                                  if col not in cols_order + ['titulo_processado', 'SLA_Horas']]
                    
                    df_display = df_filtered[cols_order]
                    
                    st.dataframe(df_display, use_container_width=True)
                    st.info(f"üìä Mostrando {len(df_filtered)} de {len(df_clustered)} registros")
                
                with tab5:
                    st.subheader("üéØ Recomenda√ß√µes para Direcionamento")
                    
                    # An√°lise de SLA cr√≠tico
                    st.write("**‚ö†Ô∏è Alertas de SLA Cr√≠tico:**")
                    p1_p2_count = len(df_clustered[df_clustered['Prioridade'].isin(['P1', 'P2'])])
                    total_count = len(df_clustered)
                    critical_percentage = (p1_p2_count / total_count) * 100
                    
                    if critical_percentage > 25:
                        st.error(f"üö® {critical_percentage:.1f}% dos chamados s√£o P1/P2 - Considere revisar os processos!")
                    elif critical_percentage > 15:
                        st.warning(f"‚ö†Ô∏è {critical_percentage:.1f}% dos chamados s√£o P1/P2 - Aten√ß√£o necess√°ria!")
                    else:
                        st.success(f"‚úÖ {critical_percentage:.1f}% dos chamados s√£o P1/P2 - Distribui√ß√£o saud√°vel!")
                    
                    # An√°lise de especializa√ß√£o por desenvolvedor
                    if 'Atribu√≠do - T√©cnico' in df_clustered.columns:
                        st.write("**üë• Sugest√µes de Especializa√ß√£o por Desenvolvedor:**")
                        
                        tecnico_cluster = df_clustered.groupby(['Atribu√≠do - T√©cnico', 'cluster']).size().reset_index(name='count')
                        
                        for cluster_id, info in clustering_system.clusters_info.items():
                            cluster_tecnicos = tecnico_cluster[tecnico_cluster['cluster'] == cluster_id]
                            if not cluster_tecnicos.empty:
                                top_tecnico = cluster_tecnicos.loc[cluster_tecnicos['count'].idxmax()]
                                priority_info = info.get('prioridade_padrao', 'P3')
                                sla_info = info.get('sla_formatado', '8h')
                                
                                st.write(f"**{info['nome']}** ({priority_info}) ‚Üí {top_tecnico['Atribu√≠do - T√©cnico']} ({top_tecnico['count']} chamados)")
                    
                    # An√°lise de carga de trabalho por prioridade
                    st.write("**üìä An√°lise de Distribui√ß√£o de Carga por Prioridade:**")
                    for cluster_id, info in clustering_system.clusters_info.items():
                        priority_info = info.get('prioridade_padrao', 'P3')
                        if priority_info in ['P1', 'P2'] and info['total_chamados'] > 10:
                            st.warning(f"‚ö†Ô∏è Cluster '{info['nome']}' ({priority_info}) tem muitos chamados cr√≠ticos ({info['total_chamados']})")
                        elif info['total_chamados'] > len(df_clustered) * 0.2:
                            st.warning(f"‚ö†Ô∏è Cluster '{info['nome']}' tem alta concentra√ß√£o ({info['total_chamados']} chamados)")
                        elif info['total_chamados'] < 5:
                            st.info(f"‚ÑπÔ∏è Cluster '{info['nome']}' tem poucos chamados ({info['total_chamados']})")
                    
                    # Recomenda√ß√µes de processo
                    st.write("**üéØ Recomenda√ß√µes de Processo:**")
                    
                    # An√°lise de sistemas cr√≠ticos
                    sistemas_criticos = df_clustered[df_clustered['Prioridade'].isin(['P1', 'P2'])]['sistema_prefix'].value_counts()
                    if not sistemas_criticos.empty:
                        st.write("**Sistemas com mais chamados cr√≠ticos:**")
                        for sistema, count in sistemas_criticos.head(3).items():
                            st.write(f"‚Ä¢ {sistema}: {count} chamados P1/P2")
                    
                    # Sugest√£o de automa√ß√£o
                    clusters_repetitivos = {k: v for k, v in clustering_system.clusters_info.items() if v['total_chamados'] > 15}
                    if clusters_repetitivos:
                        st.write("**ü§ñ Clusters candidatos √† automa√ß√£o (>15 chamados):**")
                        for cluster_id, info in clusters_repetitivos.items():
                            st.write(f"‚Ä¢ {info['nome']}: {info['total_chamados']} chamados")
                
                with tab6:
                    st.subheader("üì• Download dos Resultados")
                    
                    # Preparar dados para download
                    df_download = df_clustered.copy()
                    df_download['Nome_Cluster'] = df_download['cluster'].map(
                        lambda x: clustering_system.clusters_info[x]['nome']
                    )
                    
                    # Remover colunas t√©cnicas
                    columns_to_remove = ['titulo_processado', 'SLA_Horas']
                    df_download = df_download.drop(columns=[col for col in columns_to_remove if col in df_download.columns])
                    
                    # Reorganizar colunas
                    cols_final = ['ID', 'T√≠tulo', 'cluster', 'Nome_Cluster', 'sistema_prefix', 'Prioridade', 'SLA_Formatado', 'Impacto', 'Urgencia']
                    if 'Urg√™ncia' in df_download.columns:
                        cols_final.append('Urg√™ncia')
                    if 'Status' in df_download.columns:
                        cols_final.append('Status')
                    
                    # Adicionar outras colunas
                    cols_final += [col for col in df_download.columns if col not in cols_final]
                    
                    df_download = df_download[cols_final]
                    
                    # Estat√≠sticas do download
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üìä Total de Registros", len(df_download))
                    with col2:
                        st.metric("üéØ Clusters", df_download['cluster'].nunique())
                    with col3:
                        p1_p2_count = len(df_download[df_download['Prioridade'].isin(['P1', 'P2'])])
                        st.metric("üö® P1/P2 Cr√≠ticos", p1_p2_count)
                    with col4:
                        ai_used = st.session_state.get('use_openai', False)
                        st.metric("ü§ñ IA Utilizada", "Sim" if ai_used else "N√£o")
                    
                    # Link para download
                    download_link = create_download_link(df_download, "chamados_clusterizados_com_prioridade.xlsx")
                    st.markdown(download_link, unsafe_allow_html=True)
                    
                    st.success("‚úÖ Arquivo pronto para download com clusters e matriz de prioridade aplicados!")
                    
                    # Preview dos dados
                    st.subheader("üëÄ Preview dos Dados para Download")
                    st.dataframe(df_download.head(10), use_container_width=True)
                    
                    # Informa√ß√µes sobre o arquivo
                    st.info("""
                    **O arquivo Excel cont√©m:**
                    - Aba 'Chamados_Clusterizados': Todos os chamados com clusters e prioridades aplicadas
                    - Aba 'Resumo_Clusters': Resumo detalhado de cada cluster com SLA padr√£o
                    - Aba 'Matriz_Prioridade': Distribui√ß√£o completa da matriz Impacto x Urg√™ncia
                    - Coluna 'Prioridade': P1, P2, P3, P4, P5, Planejado, Backlog
                    - Coluna 'SLA_Formatado': Tempo de atendimento esperado
                    - Coluna 'Impacto': N√≠vel de impacto no neg√≥cio (1-5)
                    - Coluna 'Urgencia': N√≠vel de urg√™ncia temporal (1-5)
                    """)
        
        except Exception as e:
            st.error(f"‚ùå Erro ao processar arquivo: {str(e)}")
            st.exception(e)
    
    else:
        # P√°gina inicial quando n√£o h√° arquivo
        st.info("üìÅ Carregue um arquivo CSV ou Excel para come√ßar a clusteriza√ß√£o.")
        
        # Instru√ß√µes e benef√≠cios
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìã Formato do Arquivo")
            st.write("""
            **Coluna obrigat√≥ria:**
            - **T√≠tulo**: T√≠tulos dos chamados para clusteriza√ß√£o
            
            **Colunas opcionais que ser√£o preservadas:**
            - ID
            - Urg√™ncia
            - Status
            - Data de abertura
            - Atribu√≠do - T√©cnico
            - Requerente
            - Outras colunas do seu sistema
            
            **Formatos aceitos:**
            - CSV (separado por ; ou ,)
            - Excel (.xlsx, .xls)
            """)
        
        with col2:
            st.subheader("üöÄ Benef√≠cios do Sistema")
            st.write("""
            **üéØ Clusteriza√ß√£o Inteligente:**
            - Agrupa chamados similares automaticamente
            - Identifica padr√µes nos t√≠tulos
            - Facilita direcionamento para especialistas
            
            **üß≠ Matriz de Prioridade:**
            - Classifica√ß√£o autom√°tica Impacto x Urg√™ncia
            - SLAs definidos por prioridade
            - Alertas para chamados cr√≠ticos
            
            **ü§ñ Powered by AI:**
            - Usa embeddings da OpenAI para melhor precis√£o
            - Nomes de clusters gerados por IA
            - Fallback para m√©todo tradicional
            
            **üìä An√°lises Completas:**
            - Visualiza√ß√µes interativas
            - Recomenda√ß√µes de direcionamento
            - Estat√≠sticas detalhadas
            """)
        
        # Matriz de refer√™ncia
        st.subheader("üß≠ Matriz de Prioridade - Refer√™ncia")
        st.write("""
        **Escala de Impacto (1-5):**
        - **1**: Cr√≠tico - Financeiro, Faturamento, Produ√ß√£o
        - **2**: Alto - Vendas, Sistemas Principais
        - **3**: M√©dio - Administrativo, Relat√≥rios
        - **4**: Baixo - Erros visuais, Falhas pontuais
        - **5**: Muito Baixo - Melhorias, Est√©tica
        
        **Escala de Urg√™ncia (1-5):**
        - **1**: Imediato - Precisa ser resolvido agora
        - **2**: Urgente - Ainda hoje
        - **3**: Moderado - At√© 48h
        - **4**: Baixo - Na semana
        - **5**: Planej√°vel - Quando poss√≠vel
        """)
        
        # Exemplo de dados
        st.subheader("üí° Exemplo de Dados")
        example_data = {
            'ID': ['3347', '15862', '18612'],
            'T√≠tulo': [
                'SQ | Tela de log espelho do WA',
                'WA | Otimiza√ß√£o - Acompanhamento de Pe√ßa',
                'WA | Atendimento presencial'
            ],
            'Urg√™ncia': ['M√©dia', 'Alta', 'M√©dia'],
            'Status': ['Em atendimento', 'Em atendimento', 'Em atendimento']
        }
        st.dataframe(pd.DataFrame(example_data), use_container_width=True)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center'>
        <p>üéØ Sistema de Clusteriza√ß√£o GLPI com Matriz de Prioridade | Desenvolvido por Vinicius Paschoa</p>
    </div>
    """, unsafe_allow_html=True)


# Configura√ß√£o para deployment no Streamlit Cloud
if __name__ == "__main__":
    # Configura√ß√µes espec√≠ficas para Streamlit Cloud
    try:
        main()
    except Exception as e:
        st.error(f"Erro na aplica√ß√£o: {str(e)}")
        st.info("Verifique se todas as depend√™ncias est√£o instaladas e a chave da OpenAI est√° configurada nos secrets.")
